{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b5890e",
   "metadata": {},
   "source": [
    "# Toy Experiment 2: Build a RAG Application\n",
    "\n",
    "This notebook slightly differs from single-webpage-rag-application.ipynb, allowing multiple offline PDF documents as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89559500",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "%pip install openai\n",
    "%pip install -qU \"langchain[openai]\"\n",
    "%pip install -qU langchain-openai\n",
    "%pip install -qU langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916c9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pdfplumber\n",
    "%pip install semantic-text-splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f262e0e8",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56722244",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing amsterdam-facts.pdf...\n",
      "Processing amsterdam-wikipedia.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 49 page-snippets from 2 PDFs.\n",
      "Total characters: 118625\n",
      "Amsterdam, city and port, western Netherlands, located on the IJsselmeer\n",
      "and connected to the North Sea. It is the capital and the principal commercial\n",
      "and financial centre of the Netherlands.\n",
      "To the scores of tourists who visit each year, Amsterdam is known for its\n",
      "historical attractions, for its collections of great art, and for the distinctive\n",
      "colour and flavour of its old sections, which have been so well preserved.\n",
      "However, visitors to the city also see a crowded metropolis beset by\n",
      "environ\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "\n",
    "# locate the documents directory\n",
    "try:\n",
    "    base_dir = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    base_dir = Path.cwd()\n",
    "\n",
    "docs_dir = (base_dir / \"documents\").resolve()\n",
    "assert docs_dir.exists(), f\"Folder not found: {docs_dir}\"\n",
    "\n",
    "pdf_paths = sorted(docs_dir.glob(\"*.pdf\"))\n",
    "assert pdf_paths, f\"No PDFs found in: {docs_dir}\"\n",
    "\n",
    "all_documents = []  # list of dicts: {\"source\": str, \"page\": int, \"text\": str}\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    print(f\"Processing {pdf_path.name}...\")\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, start=1):\n",
    "            text = page.extract_text() or \"\"\n",
    "            text = text.strip()\n",
    "            if text:\n",
    "                all_documents.append({\n",
    "                    \"source\": pdf_path.name,\n",
    "                    \"page\": i,\n",
    "                    \"text\": text\n",
    "                })\n",
    "\n",
    "total_chars = sum(len(d[\"text\"]) for d in all_documents)\n",
    "print(f\"Loaded {len(all_documents)} page-snippets from {len(pdf_paths)} PDFs.\")\n",
    "print(f\"Total characters: {total_chars}\")\n",
    "print(all_documents[0][\"text\"][:500] if all_documents else \"No text extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98480dc9",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874ed866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 49 page-snippets into 145 chunks.\n"
     ]
    }
   ],
   "source": [
    "from semantic_text_splitter import TextSplitter\n",
    "\n",
    "max_characters = 1000\n",
    "splitter = TextSplitter(max_characters, trim=False)\n",
    "\n",
    "chunks = []\n",
    "metadatas = []\n",
    "\n",
    "for doc in all_documents:\n",
    "    sub_chunks = splitter.chunks(doc[\"text\"])\n",
    "    chunks.extend(sub_chunks)\n",
    "    metadatas.extend([{\"source\": doc[\"source\"], \"page\": doc[\"page\"]}] * len(sub_chunks))\n",
    "\n",
    "print(f\"Split {len(all_documents)} page-snippets into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5d774",
   "metadata": {},
   "source": [
    "#### Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba01cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import getpass\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f2dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 145 chunks to the vector store.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "document_ids = vector_store.add_texts(chunks, metadatas=metadatas)\n",
    "print(f\"Added {len(document_ids)} chunks to the vector store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af6dba",
   "metadata": {},
   "source": [
    "### Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116604a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is an interesting fact about Amsterdam?\"\n",
    "\n",
    "# k value as a starting point\n",
    "retrieved = vector_store.similarity_search(question, k=4)\n",
    "\n",
    "# formatting\n",
    "docs_content = \"\\n\\n\".join(\n",
    "    f\"[{i+1}] ({d.metadata.get('source')} p.{d.metadata.get('page')}):\\n{d.page_content}\"\n",
    "    for i, d in enumerate(retrieved)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3bf703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An interesting fact about Amsterdam is that it is often referred to as the \"Venice of the North\" due to its extensive and well-preserved canal system, which dates back to the city's 17th-century Golden Age [1][4]. Additionally, the Amsterdam Stock Exchange, founded in 1602, is considered the oldest \"modern\" securities market in the world [4]. The city's combination of historical significance and modern financial prowess makes it a unique destination [2].\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use ONLY the reference numbers provided in the context (e.g., [1], [2]) \n",
    "when citing information. Do not invent new references.\n",
    "Answer in three sentences maximum.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "rendered = prompt.format(question=question, context=docs_content)\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "answer = llm.invoke(rendered).content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f532a48",
   "metadata": {},
   "source": [
    "Let's check that the model is not hallucinating the references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b5f5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -> amsterdam-wikipedia.pdf (page 1)\n",
      "[4] -> amsterdam-wikipedia.pdf (page 1)\n",
      "[4] -> amsterdam-wikipedia.pdf (page 1)\n",
      "[2] -> amsterdam-facts.pdf (page 1)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "refs = re.findall(r\"\\[(\\d+)\\]\", answer)\n",
    "for r in refs:\n",
    "    idx = int(r) - 1\n",
    "    if 0 <= idx < len(retrieved):\n",
    "        meta = retrieved[idx].metadata\n",
    "        print(f\"[{r}] -> {meta['source']} (page {meta['page']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
