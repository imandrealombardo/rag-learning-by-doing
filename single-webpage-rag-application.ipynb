{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6c8f6d",
   "metadata": {},
   "source": [
    "# Toy Experiment: Build a RAG Application\n",
    "\n",
    "This notebook is inspired by Langchain's [RAG tutorial](https://python.langchain.com/docs/get_started/quickstart). Key differences:\n",
    "- Instead of LangChain's WebLoader, we will use trafilatura.\n",
    "- Instead of LangChain's Text splitter, we will use semantic-text-splitter.\n",
    "- Instead of LangChain's LangGraph, we will implement the same application logic (in Retrieval and Generation part) through invocations of the individual components\n",
    "\n",
    "The reason of these changes is to reduce dependency from LangChain and better understand how the process works.\n",
    "\n",
    "Note: This notebook focuses on the retrieval of a single web page. In the next notebook, we will extend it to multiple web pages and offline files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb1ab4",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "%pip install openai\n",
    "%pip install -qU \"langchain[openai]\"\n",
    "%pip install -qU langchain-openai\n",
    "%pip install -qU langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de42ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install trafilatura\n",
    "%pip install semantic-text-splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a8527",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249e303",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89f8f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 4004\n",
      "Het Bosch restaurant\n",
      "Lounge in style while taking in the spectacular view of the Nieuwe Meer lake. French-Mediterranean cuisine offering lunch and dinner options. Regularly features live music. Open from Monday to Saturday. Lunch is served from 12.00 am to 3:00 pm. Dinner from 6.00 pm to 10.00 pm (on Saturday from 7.00 pm to 10.00 pm). Price indication: approx. € 50 for a four course meal. For reservations call +31 (0) 20 644 58 00.\n",
      "Restaurant De Bosbaan\n",
      "Escape the city and enjoy the view of the\n"
     ]
    }
   ],
   "source": [
    "import trafilatura\n",
    "from semantic_text_splitter import TextSplitter\n",
    "\n",
    "url = \"https://www.amsterdamsebos.nl/english/eat/\"\n",
    "downloaded = trafilatura.fetch_url(url)\n",
    "text = trafilatura.extract(downloaded)\n",
    "\n",
    "print(f\"Total characters: {len(text)}\")\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4905e9",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e18d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 5 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "max_characters = 1000\n",
    "splitter = TextSplitter(max_characters, trim=False)\n",
    "chunks = splitter.chunks(text)\n",
    "\n",
    "print(f\"Split blog post into {len(chunks)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b18f8d",
   "metadata": {},
   "source": [
    "#### Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41b99c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import getpass\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62506f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "document_ids = vector_store.add_texts(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0592ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 5 documents to the vector store.\n",
      "['5be065d4-17a6-4594-be7b-e2c89ba26dda', '4af8e730-817e-4da3-a30d-1a6be592464c', '8243f805-3753-4fdb-bcc2-b683db00aad2', 'd132baa3-6097-4185-aba3-aa7f02569559', '3157ab94-d971-4cbc-b75b-2acd3202a6ec']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Added {len(document_ids)} documents to the vector store.\")\n",
    "print(document_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e901d",
   "metadata": {},
   "source": [
    "### Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b16d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 4 documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "question = \"Where can I find a restaurant in Amsterdamse Bos that serves pancakes?\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question)\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents.\")\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10676e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Manually render the prompt (no abstraction)\n",
    "rendered = prompt.format(question=question, context=docs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba10d78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: You can find traditional Dutch pancakes at Paviljoen Aquarius in Amsterdamse Bos. They are open from Wednesday to Sunday, with varied hours depending on the season. Prices start at €6.50 for a bacon pancake with syrup.\n",
      "Answer length: 218 characters\n"
     ]
    }
   ],
   "source": [
    "# Pass the rendered string directly to the model\n",
    "# (Chat models accept strings; LangChain wraps it as a HumanMessage internally)\n",
    "answer = llm.invoke(rendered).content\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Answer length: {len(answer)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72511116",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "This notebook has the following limitations:\n",
    "- It does not support offline files or multiple web pages.\n",
    "- It does not support multiple questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
